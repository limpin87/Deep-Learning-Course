{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CycleGAN Notebook for Style Transfer\n",
    "## In this notebook, CycleGAN is used to generate images from different domains.\n",
    "### Experimented Domains:\n",
    "- Real building Architecture to Steampunk building design\n",
    "- Season generation\n",
    "\n",
    "Note: This notebook is based heavily on the CycleGAN Repositiory by https://github.com/xhujoy/CycleGAN-tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, math\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "import argparse\n",
    "from progressbar import ProgressBar\n",
    "tf.set_random_seed(19)\n",
    "\n",
    "from module import *\n",
    "from utils import *\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--test_dir'], dest='test_dir', nargs=None, const=None, default='./test', type=None, choices=None, help='test sample are saved here', metavar=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dir = 'Autumn2Summer'   # Dataset dir\n",
    "checkpoint_dir = './checkpoints/'  # checkpoint_dir\n",
    "result_dir = './results/'          # result_dir\n",
    "log_dir = './logs/'                # log_dir\n",
    "sample_dir = './sample/'           # sample_dir\n",
    "\n",
    "epoches = 200                     # Number of Epoches\n",
    "batch_size = 1                     # Batch_size\n",
    "epoch_step = 100                   # Number of epoch to decay lr\n",
    "init_learn_rate = 0.0002           # Initial learning rate for adam\n",
    "beta1 = 0.5\n",
    "L1_lambda = 10.0\n",
    "max_pool = 50                      # Max size of image pool\n",
    "\n",
    "# input parameters\n",
    "input_height = 256\n",
    "input_width = 256\n",
    "input_nc =3\n",
    "output_height = 256\n",
    "output_width = 256\n",
    "output_nc = 3\n",
    "\n",
    "ngf = 64\n",
    "ndf= 64\n",
    "\n",
    "save_freq = 10\n",
    "print_freq = 10\n",
    "\n",
    "# test\n",
    "\n",
    "parser = argparse.ArgumentParser(description='')\n",
    "parser.add_argument('--train_size', dest='train_size', type=int, default=1e8, help='# images used to train')\n",
    "parser.add_argument('--load_size', dest='load_size', type=int, default=286, help='scale images to this size')\n",
    "parser.add_argument('--fine_size', dest='fine_size', type=int, default=256, help='then crop to this size')\n",
    "parser.add_argument('--beta1', dest='beta1', type=float, default=0.5, help='momentum term of adam')\n",
    "parser.add_argument('--which_direction', dest='which_direction', default='AtoB', help='AtoB or BtoA')\n",
    "parser.add_argument('--phase', dest='phase', default='train', help='train, test')\n",
    "parser.add_argument('--save_freq', dest='save_freq', type=int, default=1000, help='save a model every save_freq iterations')\n",
    "parser.add_argument('--print_freq', dest='print_freq', type=int, default=100, help='print the debug information every print_freq iterations')\n",
    "parser.add_argument('--continue_train', dest='continue_train', type=bool, default=False, help='if continue training, load the latest model: 1: true, 0: false')\n",
    "parser.add_argument('--test_dir', dest='test_dir', default='./test', help='test sample are saved here')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save(self, checkpoint_dir, step):\n",
    "    model_name = \"cyclegan.model\"\n",
    "    model_dir = \"%s_%s\" % (self.dataset_dir, self.image_size)\n",
    "    checkpoint_dir = os.path.join(checkpoint_dir, model_dir)\n",
    "\n",
    "    if not os.path.exists(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir)\n",
    "\n",
    "    saver.save(sess,\n",
    "                    os.path.join(checkpoint_dir, model_name),\n",
    "                    global_step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfconfig = tf.ConfigProto(allow_soft_placement=True)\n",
    "tfconfig.gpu_options.allow_growth = True\n",
    "\n",
    "# with tf.Session(config=tfconfig) as sess:\n",
    "sess = tf.Session(config=tfconfig)\n",
    "#model = cyclegan(sess, args)\n",
    "\n",
    "discriminator = discriminator\n",
    "generator = generator_resnet # generator_unet\n",
    "criterionGAN = mae_criterion # abs_criterion\n",
    "\n",
    "OPTIONS = namedtuple('OPTIONS', 'batch_size image_size gf_dim df_dim output_c_dim ')\n",
    "options = OPTIONS._make((batch_size,input_height,ngf,ndf,output_nc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generatorA2B/g_e1_c/Conv/weights:0\n",
      "generatorA2B/g_e1_bn/scale:0\n",
      "generatorA2B/g_e1_bn/offset:0\n",
      "generatorA2B/g_e2_c/Conv/weights:0\n",
      "generatorA2B/g_e2_bn/scale:0\n",
      "generatorA2B/g_e2_bn/offset:0\n",
      "generatorA2B/g_e3_c/Conv/weights:0\n",
      "generatorA2B/g_e3_bn/scale:0\n",
      "generatorA2B/g_e3_bn/offset:0\n",
      "generatorA2B/g_r1_c1/Conv/weights:0\n",
      "generatorA2B/g_r1_bn1/scale:0\n",
      "generatorA2B/g_r1_bn1/offset:0\n",
      "generatorA2B/g_r1_c2/Conv/weights:0\n",
      "generatorA2B/g_r1_bn2/scale:0\n",
      "generatorA2B/g_r1_bn2/offset:0\n",
      "generatorA2B/g_r2_c1/Conv/weights:0\n",
      "generatorA2B/g_r2_bn1/scale:0\n",
      "generatorA2B/g_r2_bn1/offset:0\n",
      "generatorA2B/g_r2_c2/Conv/weights:0\n",
      "generatorA2B/g_r2_bn2/scale:0\n",
      "generatorA2B/g_r2_bn2/offset:0\n",
      "generatorA2B/g_r3_c1/Conv/weights:0\n",
      "generatorA2B/g_r3_bn1/scale:0\n",
      "generatorA2B/g_r3_bn1/offset:0\n",
      "generatorA2B/g_r3_c2/Conv/weights:0\n",
      "generatorA2B/g_r3_bn2/scale:0\n",
      "generatorA2B/g_r3_bn2/offset:0\n",
      "generatorA2B/g_r4_c1/Conv/weights:0\n",
      "generatorA2B/g_r4_bn1/scale:0\n",
      "generatorA2B/g_r4_bn1/offset:0\n",
      "generatorA2B/g_r4_c2/Conv/weights:0\n",
      "generatorA2B/g_r4_bn2/scale:0\n",
      "generatorA2B/g_r4_bn2/offset:0\n",
      "generatorA2B/g_r5_c1/Conv/weights:0\n",
      "generatorA2B/g_r5_bn1/scale:0\n",
      "generatorA2B/g_r5_bn1/offset:0\n",
      "generatorA2B/g_r5_c2/Conv/weights:0\n",
      "generatorA2B/g_r5_bn2/scale:0\n",
      "generatorA2B/g_r5_bn2/offset:0\n",
      "generatorA2B/g_r6_c1/Conv/weights:0\n",
      "generatorA2B/g_r6_bn1/scale:0\n",
      "generatorA2B/g_r6_bn1/offset:0\n",
      "generatorA2B/g_r6_c2/Conv/weights:0\n",
      "generatorA2B/g_r6_bn2/scale:0\n",
      "generatorA2B/g_r6_bn2/offset:0\n",
      "generatorA2B/g_r7_c1/Conv/weights:0\n",
      "generatorA2B/g_r7_bn1/scale:0\n",
      "generatorA2B/g_r7_bn1/offset:0\n",
      "generatorA2B/g_r7_c2/Conv/weights:0\n",
      "generatorA2B/g_r7_bn2/scale:0\n",
      "generatorA2B/g_r7_bn2/offset:0\n",
      "generatorA2B/g_r8_c1/Conv/weights:0\n",
      "generatorA2B/g_r8_bn1/scale:0\n",
      "generatorA2B/g_r8_bn1/offset:0\n",
      "generatorA2B/g_r8_c2/Conv/weights:0\n",
      "generatorA2B/g_r8_bn2/scale:0\n",
      "generatorA2B/g_r8_bn2/offset:0\n",
      "generatorA2B/g_r9_c1/Conv/weights:0\n",
      "generatorA2B/g_r9_bn1/scale:0\n",
      "generatorA2B/g_r9_bn1/offset:0\n",
      "generatorA2B/g_r9_c2/Conv/weights:0\n",
      "generatorA2B/g_r9_bn2/scale:0\n",
      "generatorA2B/g_r9_bn2/offset:0\n",
      "generatorA2B/g_d1_dc/Conv2d_transpose/weights:0\n",
      "generatorA2B/g_d1_bn/scale:0\n",
      "generatorA2B/g_d1_bn/offset:0\n",
      "generatorA2B/g_d2_dc/Conv2d_transpose/weights:0\n",
      "generatorA2B/g_d2_bn/scale:0\n",
      "generatorA2B/g_d2_bn/offset:0\n",
      "generatorA2B/g_pred_c/Conv/weights:0\n",
      "generatorB2A/g_e1_c/Conv/weights:0\n",
      "generatorB2A/g_e1_bn/scale:0\n",
      "generatorB2A/g_e1_bn/offset:0\n",
      "generatorB2A/g_e2_c/Conv/weights:0\n",
      "generatorB2A/g_e2_bn/scale:0\n",
      "generatorB2A/g_e2_bn/offset:0\n",
      "generatorB2A/g_e3_c/Conv/weights:0\n",
      "generatorB2A/g_e3_bn/scale:0\n",
      "generatorB2A/g_e3_bn/offset:0\n",
      "generatorB2A/g_r1_c1/Conv/weights:0\n",
      "generatorB2A/g_r1_bn1/scale:0\n",
      "generatorB2A/g_r1_bn1/offset:0\n",
      "generatorB2A/g_r1_c2/Conv/weights:0\n",
      "generatorB2A/g_r1_bn2/scale:0\n",
      "generatorB2A/g_r1_bn2/offset:0\n",
      "generatorB2A/g_r2_c1/Conv/weights:0\n",
      "generatorB2A/g_r2_bn1/scale:0\n",
      "generatorB2A/g_r2_bn1/offset:0\n",
      "generatorB2A/g_r2_c2/Conv/weights:0\n",
      "generatorB2A/g_r2_bn2/scale:0\n",
      "generatorB2A/g_r2_bn2/offset:0\n",
      "generatorB2A/g_r3_c1/Conv/weights:0\n",
      "generatorB2A/g_r3_bn1/scale:0\n",
      "generatorB2A/g_r3_bn1/offset:0\n",
      "generatorB2A/g_r3_c2/Conv/weights:0\n",
      "generatorB2A/g_r3_bn2/scale:0\n",
      "generatorB2A/g_r3_bn2/offset:0\n",
      "generatorB2A/g_r4_c1/Conv/weights:0\n",
      "generatorB2A/g_r4_bn1/scale:0\n",
      "generatorB2A/g_r4_bn1/offset:0\n",
      "generatorB2A/g_r4_c2/Conv/weights:0\n",
      "generatorB2A/g_r4_bn2/scale:0\n",
      "generatorB2A/g_r4_bn2/offset:0\n",
      "generatorB2A/g_r5_c1/Conv/weights:0\n",
      "generatorB2A/g_r5_bn1/scale:0\n",
      "generatorB2A/g_r5_bn1/offset:0\n",
      "generatorB2A/g_r5_c2/Conv/weights:0\n",
      "generatorB2A/g_r5_bn2/scale:0\n",
      "generatorB2A/g_r5_bn2/offset:0\n",
      "generatorB2A/g_r6_c1/Conv/weights:0\n",
      "generatorB2A/g_r6_bn1/scale:0\n",
      "generatorB2A/g_r6_bn1/offset:0\n",
      "generatorB2A/g_r6_c2/Conv/weights:0\n",
      "generatorB2A/g_r6_bn2/scale:0\n",
      "generatorB2A/g_r6_bn2/offset:0\n",
      "generatorB2A/g_r7_c1/Conv/weights:0\n",
      "generatorB2A/g_r7_bn1/scale:0\n",
      "generatorB2A/g_r7_bn1/offset:0\n",
      "generatorB2A/g_r7_c2/Conv/weights:0\n",
      "generatorB2A/g_r7_bn2/scale:0\n",
      "generatorB2A/g_r7_bn2/offset:0\n",
      "generatorB2A/g_r8_c1/Conv/weights:0\n",
      "generatorB2A/g_r8_bn1/scale:0\n",
      "generatorB2A/g_r8_bn1/offset:0\n",
      "generatorB2A/g_r8_c2/Conv/weights:0\n",
      "generatorB2A/g_r8_bn2/scale:0\n",
      "generatorB2A/g_r8_bn2/offset:0\n",
      "generatorB2A/g_r9_c1/Conv/weights:0\n",
      "generatorB2A/g_r9_bn1/scale:0\n",
      "generatorB2A/g_r9_bn1/offset:0\n",
      "generatorB2A/g_r9_c2/Conv/weights:0\n",
      "generatorB2A/g_r9_bn2/scale:0\n",
      "generatorB2A/g_r9_bn2/offset:0\n",
      "generatorB2A/g_d1_dc/Conv2d_transpose/weights:0\n",
      "generatorB2A/g_d1_bn/scale:0\n",
      "generatorB2A/g_d1_bn/offset:0\n",
      "generatorB2A/g_d2_dc/Conv2d_transpose/weights:0\n",
      "generatorB2A/g_d2_bn/scale:0\n",
      "generatorB2A/g_d2_bn/offset:0\n",
      "generatorB2A/g_pred_c/Conv/weights:0\n",
      "discriminatorB/d_h0_conv/Conv/weights:0\n",
      "discriminatorB/d_h1_conv/Conv/weights:0\n",
      "discriminatorB/d_bn1/scale:0\n",
      "discriminatorB/d_bn1/offset:0\n",
      "discriminatorB/d_h2_conv/Conv/weights:0\n",
      "discriminatorB/d_bn2/scale:0\n",
      "discriminatorB/d_bn2/offset:0\n",
      "discriminatorB/d_h3_conv/Conv/weights:0\n",
      "discriminatorB/d_bn3/scale:0\n",
      "discriminatorB/d_bn3/offset:0\n",
      "discriminatorB/d_h3_pred/Conv/weights:0\n",
      "discriminatorA/d_h0_conv/Conv/weights:0\n",
      "discriminatorA/d_h1_conv/Conv/weights:0\n",
      "discriminatorA/d_bn1/scale:0\n",
      "discriminatorA/d_bn1/offset:0\n",
      "discriminatorA/d_h2_conv/Conv/weights:0\n",
      "discriminatorA/d_bn2/scale:0\n",
      "discriminatorA/d_bn2/offset:0\n",
      "discriminatorA/d_h3_conv/Conv/weights:0\n",
      "discriminatorA/d_bn3/scale:0\n",
      "discriminatorA/d_bn3/offset:0\n",
      "discriminatorA/d_h3_pred/Conv/weights:0\n"
     ]
    }
   ],
   "source": [
    "#### Start of building the model ####\n",
    "real_data = tf.placeholder(tf.float32,[None, input_height, input_width,\n",
    "                                     input_nc + output_nc],name='real_A_and_B_images')\n",
    "\n",
    "real_A = real_data[:, :, :, :input_nc]\n",
    "real_B = real_data[:, :, :, input_nc:input_nc + output_nc]\n",
    "\n",
    "fake_B = generator(real_A, options, False, name=\"generatorA2B\")\n",
    "fake_A_ = generator(fake_B, options, False, name=\"generatorB2A\")\n",
    "fake_A = generator(real_B, options, True, name=\"generatorB2A\")\n",
    "fake_B_ = generator(fake_A, options, True, name=\"generatorA2B\")\n",
    "\n",
    "DB_fake = discriminator(fake_B, options, reuse=False, name=\"discriminatorB\")\n",
    "DA_fake = discriminator(fake_A, options, reuse=False, name=\"discriminatorA\")\n",
    "\n",
    "g_loss_a2b = criterionGAN(DB_fake, tf.ones_like(DB_fake)) \\\n",
    "            + L1_lambda * abs_criterion(real_A, fake_A_) + L1_lambda * abs_criterion(real_B, fake_B_)\n",
    "g_loss_b2a = criterionGAN(DA_fake, tf.ones_like(DA_fake)) \\\n",
    "            + L1_lambda * abs_criterion(real_A, fake_A_) + L1_lambda * abs_criterion(real_B, fake_B_)\n",
    "g_loss = criterionGAN(DA_fake, tf.ones_like(DA_fake)) + criterionGAN(DB_fake, tf.ones_like(DB_fake)) \\\n",
    "            + L1_lambda * abs_criterion(real_A, fake_A_) + L1_lambda * abs_criterion(real_B, fake_B_)\n",
    "\n",
    "fake_A_sample = tf.placeholder(tf.float32,[None, input_height, input_width, input_nc], name='fake_A_sample')\n",
    "fake_B_sample = tf.placeholder(tf.float32,[None, output_height, output_width, output_nc], name='fake_B_sample')\n",
    "\n",
    "DB_real = discriminator(real_B, options, reuse=True, name=\"discriminatorB\")\n",
    "DA_real = discriminator(real_A, options, reuse=True, name=\"discriminatorA\")\n",
    "DB_fake_sample = discriminator(fake_B_sample, options, reuse=True, name=\"discriminatorB\")\n",
    "DA_fake_sample = discriminator(fake_A_sample, options, reuse=True, name=\"discriminatorA\")\n",
    "\n",
    "db_loss_real = criterionGAN(DB_real, tf.ones_like(DB_real))\n",
    "db_loss_fake = criterionGAN(DB_fake_sample, tf.zeros_like(DB_fake_sample))\n",
    "db_loss = (db_loss_real + db_loss_fake) / 2\n",
    "\n",
    "da_loss_real = criterionGAN(DA_real, tf.ones_like(DA_real))\n",
    "da_loss_fake = criterionGAN(DA_fake_sample, tf.zeros_like(DA_fake_sample))\n",
    "da_loss = (da_loss_real + da_loss_fake) / 2\n",
    "\n",
    "d_loss = da_loss + db_loss\n",
    "\n",
    "g_loss_a2b_sum = tf.summary.scalar(\"g_loss_a2b\", g_loss_a2b)\n",
    "g_loss_b2a_sum = tf.summary.scalar(\"g_loss_b2a\", g_loss_b2a)\n",
    "g_loss_sum = tf.summary.scalar(\"g_loss\", g_loss)\n",
    "g_sum = tf.summary.merge([g_loss_a2b_sum, g_loss_b2a_sum, g_loss_sum])\n",
    "\n",
    "db_loss_sum = tf.summary.scalar(\"db_loss\", db_loss)\n",
    "da_loss_sum = tf.summary.scalar(\"da_loss\", da_loss)\n",
    "d_loss_sum = tf.summary.scalar(\"d_loss\", d_loss)\n",
    "\n",
    "db_loss_real_sum = tf.summary.scalar(\"db_loss_real\", db_loss_real)\n",
    "db_loss_fake_sum = tf.summary.scalar(\"db_loss_fake\", db_loss_fake)\n",
    "\n",
    "da_loss_real_sum = tf.summary.scalar(\"da_loss_real\", da_loss_real)\n",
    "da_loss_fake_sum = tf.summary.scalar(\"da_loss_fake\", da_loss_fake)\n",
    "\n",
    "d_sum = tf.summary.merge([da_loss_sum, da_loss_real_sum, da_loss_fake_sum,\n",
    "                          db_loss_sum, db_loss_real_sum, db_loss_fake_sum, d_loss_sum])\n",
    "\n",
    "test_A = tf.placeholder(tf.float32,[None, input_height, input_width, input_nc], name='test_A')\n",
    "test_B = tf.placeholder(tf.float32,[None, output_height, output_width, output_nc], name='test_B')\n",
    "\n",
    "testB = generator(test_A, options, True, name=\"generatorA2B\")\n",
    "testA = generator(test_B, options, True, name=\"generatorB2A\")\n",
    "\n",
    "t_vars = tf.trainable_variables()\n",
    "d_vars = [var for var in t_vars if 'discriminator' in var.name]\n",
    "g_vars = [var for var in t_vars if 'generator' in var.name]\n",
    "for var in t_vars: print(var.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13% (101 of 740) |###                    | Elapsed Time: 0:03:25 ETA:  0:19:12"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "pool = ImagePool(max_pool)\n",
    "\n",
    "#### Train cyclegan ####\n",
    "learn_rate = tf.placeholder(tf.float32, None, name='learning_rate')\n",
    "d_optim = tf.train.AdamOptimizer(learn_rate, beta1).minimize(d_loss, var_list=d_vars)\n",
    "g_optim = tf.train.AdamOptimizer(learn_rate, beta1).minimize(g_loss, var_list=g_vars)\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess.run(init_op)\n",
    "writer = tf.summary.FileWriter(\"./logs\", sess.graph)\n",
    "\n",
    "counter = 1\n",
    "start_time = time.time()\n",
    "bar =ProgressBar(redirect_stdout=True)\n",
    "\n",
    "for epoch in range(epoches):\n",
    "\n",
    "    dataA = glob('./datasets/{}/*.*'.format(dataset_dir + '/trainA'))\n",
    "    dataB = glob('./datasets/{}/*.*'.format(dataset_dir + '/trainB'))\n",
    "    np.random.shuffle(dataA)\n",
    "    np.random.shuffle(dataB)\n",
    "\n",
    "    batch_idxs = min(len(dataA), len(dataB)) // batch_size\n",
    "    lr = init_learn_rate if epoch < epoch_step else init_learn_rate*(epoches-epoch)/(epoches-epoch_step)\n",
    "\n",
    "    for idx in bar(range(0, batch_idxs)):\n",
    "        batch_files = list(zip(dataA[idx * batch_size:(idx + 1) * batch_size],\n",
    "                               dataB[idx * batch_size:(idx + 1) * batch_size]))\n",
    "        batch_images = [load_train_data(batch_file, 286, 256) for batch_file in batch_files]\n",
    "        batch_images = np.array(batch_images).astype(np.float32)\n",
    "#             print batch_images\n",
    "\n",
    "        # Update G network and record fake outputs\n",
    "        e_fake_A, e_fake_B, _, summary_str = sess.run([fake_A, fake_B, g_optim, g_sum], \n",
    "                                                  feed_dict={real_data: batch_images, learn_rate: lr})\n",
    "        writer.add_summary(summary_str, counter)\n",
    "        [e_fake_A, e_fake_B] = pool([e_fake_A, e_fake_B])\n",
    "\n",
    "        # Update D network\n",
    "        _, summary_str = sess.run([d_optim, d_sum],feed_dict={real_data: batch_images, fake_A_sample: e_fake_A,\n",
    "                                   fake_B_sample: e_fake_B, learn_rate: lr})\n",
    "        writer.add_summary(summary_str, counter)\n",
    "\n",
    "        counter += 1\n",
    "#         print \"Epoch: [%2d]\" %epoch ,idx\n",
    "#         bar.update(idx)\n",
    "#         print((\"Epoch: [%2d] [%4d/%4d] time: %4.4f\" % (\n",
    "#             epoch, idx, batch_idxs, time.time() - start_time)))\n",
    "\n",
    "        if np.mod(epoch, print_freq) == 1:\n",
    "#                 sample_model(sample_dir, epoch, idx) ## Print these out instead\n",
    "            vdataA = glob('./datasets/{}/*.*'.format(dataset_dir + '/testA'))\n",
    "            vdataB = glob('./datasets/{}/*.*'.format(dataset_dir + '/testB'))\n",
    "            np.random.shuffle(vdataA)\n",
    "            np.random.shuffle(vdataB)\n",
    "            vbatch_files = list(zip(vdataA[:batch_size], vdataB[:batch_size]))\n",
    "            sample_images = [load_train_data(vbatch_file, is_testing=True) for vbatch_file in vbatch_files]\n",
    "            sample_images = np.array(sample_images).astype(np.float32)\n",
    "\n",
    "            vfake_A, vfake_B = sess.run([fake_A, fake_B],feed_dict={real_data: sample_images})\n",
    "            imgA = imread(vbatch_file[0]) ; imgB = imread(vbatch_file[1])\n",
    "            imgA = scipy.misc.imresize(imgA, [256, 256]) ; imgB = scipy.misc.imresize(imgB, [256, 256])\n",
    "\n",
    "            ## Start of Plotting\n",
    "            plt.figure(figsize=(10,5))\n",
    "            plt.subplot(1,2,1); plt.imshow(imgA)\n",
    "            plt.title('Original Image')\n",
    "            plt.subplot(1,2,2); plt.imshow((vfake_A[0]+1.)/2.)\n",
    "            plt.title('Epoch: %d; Style Transferred Image' %epoch )\n",
    "\n",
    "            plt.figure(figsize=(10,5))\n",
    "            plt.subplot(1,2,1); plt.imshow(imgB)\n",
    "            plt.title('Original Image')\n",
    "            plt.subplot(1,2,2); plt.imshow((vfake_B[0]+1.)/2.)\n",
    "            plt.title('Epoch: %d; Style Transferred Image' %epoch )\n",
    "\n",
    "        if np.mod(epoch, save_freq) == 2:\n",
    "#                 save(checkpoint_dir, counter)\n",
    "            model_name = \"cyclegan.model\"\n",
    "            model_dir = \"%s_%s\" % (dataset_dir, 256)\n",
    "            checkpoint_dir = os.path.join(checkpoint_dir, model_dir)\n",
    "\n",
    "            if not os.path.exists(checkpoint_dir):\n",
    "                os.makedirs(checkpoint_dir)\n",
    "            saver.save(sess,os.path.join(checkpoint_dir, model_name),global_step=counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing all images at the end of the training\n",
    "vdataA = glob('./datasets/{}/*.*'.format(dataset_dir + '/testA'))\n",
    "vdataB = glob('./datasets/{}/*.*'.format(dataset_dir + '/testB'))\n",
    "vbatch_files = list(zip(vdataA, vdataB))\n",
    "sample_images = [load_train_data(vbatch_file, is_testing=True) for vbatch_file in vbatch_files]\n",
    "sample_images = np.array(sample_images).astype(np.float32)\n",
    "\n",
    "vfake_A, vfake_B = sess.run([fake_A, fake_B],feed_dict={real_data: sample_images})\n",
    "for i, vbatch_file in enumerate(vbatch_files):\n",
    "    imgA = imread(vbatch_file[0]) ; imgB = imread(vbatch_file[1])\n",
    "    imgA = scipy.misc.imresize(imgA, [256, 256]) ; imgB = scipy.misc.imresize(imgB, [256, 256])\n",
    "\n",
    "    ## Start of Plotting\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.subplot(1,2,1); plt.imshow(imgA)\n",
    "    plt.title('Original Image No: %d'%i)\n",
    "    plt.subplot(1,2,2); plt.imshow((vfake_B[i]+1.)/2.)\n",
    "    plt.title('Style Transferred Image No: %d'%i)\n",
    "\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.subplot(1,2,1); plt.imshow(imgB)\n",
    "    plt.title('Original Image No: %d'%i)\n",
    "    plt.subplot(1,2,2); plt.imshow((vfake_A[i]+1.)/2.)\n",
    "    plt.title('Style Transferred Image No: %d'%i )\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
