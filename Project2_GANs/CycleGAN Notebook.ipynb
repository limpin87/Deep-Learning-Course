{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CycleGAN Notebook for Style Transfer\n",
    "## In this notebook, CycleGAN is used to generate images from different domains.\n",
    "### Experimented Domains:\n",
    "- Real building Architecture to Steampunk building design\n",
    "- Season generation\n",
    "\n",
    "Note: This notebook is based heavily on the CycleGAN Repositiory by https://github.com/xhujoy/CycleGAN-tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, math\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "import argparse\n",
    "tf.set_random_seed(19)\n",
    "# from model import cyclegan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--test_dir'], dest='test_dir', nargs=None, const=None, default='./test', type=None, choices=None, help='test sample are saved here', metavar=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dir = 'monet2photosmall'   # Dataset dir\n",
    "checkpoint_dir = './checkpoints/'  # checkpoint_dir\n",
    "result_dir = './results/'          # result_dir\n",
    "log_dir = './logs/'                # log_dir\n",
    "sample_dir = './sample/'           # sample_dir\n",
    "\n",
    "epoches = 10                         # Number of Epoches\n",
    "batch_size = 32                    # Batch_size\n",
    "epoch_step = 100                   # Number of epoch to decay lr\n",
    "init_learn_rate = 0.0002                        # Initial learning rate for adam\n",
    "beta1 = 0.5\n",
    "L1_lambda = 10.0\n",
    "max_pool = 50                      # Max size of image pool\n",
    "\n",
    "# input parameters\n",
    "input_height = 256\n",
    "input_width = 256\n",
    "input_nc =3\n",
    "output_height = 256\n",
    "output_width = 256\n",
    "output_nc = 3\n",
    "\n",
    "ngf = 64\n",
    "ndf= 64\n",
    "\n",
    "# z_dim = 100       # dimension of noise-vector\n",
    "# c_dim = 3\n",
    "\n",
    "# test\n",
    "sample_num = 64  # number of generated images to be saved\n",
    "\n",
    "parser = argparse.ArgumentParser(description='')\n",
    "# parser.add_argument('--dataset_dir', dest='dataset_dir', default='horse2zebra', help='path of the dataset')\n",
    "# parser.add_argument('--epoch', dest='epoch', type=int, default=200, help='# of epoch')\n",
    "# parser.add_argument('--epoch_step', dest='epoch_step', type=int, default=100, help='# of epoch to decay lr')\n",
    "# parser.add_argument('--batch_size', dest='batch_size', type=int, default=1, help='# images in batch')\n",
    "parser.add_argument('--train_size', dest='train_size', type=int, default=1e8, help='# images used to train')\n",
    "parser.add_argument('--load_size', dest='load_size', type=int, default=286, help='scale images to this size')\n",
    "parser.add_argument('--fine_size', dest='fine_size', type=int, default=256, help='then crop to this size')\n",
    "# parser.add_argument('--ngf', dest='ngf', type=int, default=64, help='# of gen filters in first conv layer')\n",
    "# parser.add_argument('--ndf', dest='ndf', type=int, default=64, help='# of discri filters in first conv layer')\n",
    "# parser.add_argument('--input_nc', dest='input_nc', type=int, default=3, help='# of input image channels')\n",
    "# parser.add_argument('--output_nc', dest='output_nc', type=int, default=3, help='# of output image channels')\n",
    "# parser.add_argument('--lr', dest='lr', type=float, default=0.0002, help='initial learning rate for adam')\n",
    "parser.add_argument('--beta1', dest='beta1', type=float, default=0.5, help='momentum term of adam')\n",
    "parser.add_argument('--which_direction', dest='which_direction', default='AtoB', help='AtoB or BtoA')\n",
    "parser.add_argument('--phase', dest='phase', default='train', help='train, test')\n",
    "parser.add_argument('--save_freq', dest='save_freq', type=int, default=1000, help='save a model every save_freq iterations')\n",
    "parser.add_argument('--print_freq', dest='print_freq', type=int, default=100, help='print the debug information every print_freq iterations')\n",
    "parser.add_argument('--continue_train', dest='continue_train', type=bool, default=False, help='if continue training, load the latest model: 1: true, 0: false')\n",
    "# parser.add_argument('--checkpoint_dir', dest='checkpoint_dir', default='./checkpoint', help='models are saved here')\n",
    "# parser.add_argument('--sample_dir', dest='sample_dir', default='./sample', help='sample are saved here')\n",
    "parser.add_argument('--test_dir', dest='test_dir', default='./test', help='test sample are saved here')\n",
    "# parser.add_argument('--L1_lambda', dest='L1_lambda', type=float, default=10.0, help='weight on L1 term in objective')\n",
    "# parser.add_argument('--use_resnet', dest='use_resnet', type=bool, default=True, help='generation network using reidule block')\n",
    "# parser.add_argument('--use_lsgan', dest='use_lsgan', type=bool, default=True, help='gan loss defined in lsgan')\n",
    "# parser.add_argument('--max_size', dest='max_size', type=int, default=50, help='max size of image pool, 0 means do not use image pool')\n",
    "\n",
    "# args = parser.parse_args()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generatorA2B/g_e1_c/Conv/weights:0\n",
      "generatorA2B/g_e1_bn/scale:0\n",
      "generatorA2B/g_e1_bn/offset:0\n",
      "generatorA2B/g_e2_c/Conv/weights:0\n",
      "generatorA2B/g_e2_bn/scale:0\n",
      "generatorA2B/g_e2_bn/offset:0\n",
      "generatorA2B/g_e3_c/Conv/weights:0\n",
      "generatorA2B/g_e3_bn/scale:0\n",
      "generatorA2B/g_e3_bn/offset:0\n",
      "generatorA2B/g_r1_c1/Conv/weights:0\n",
      "generatorA2B/g_r1_bn1/scale:0\n",
      "generatorA2B/g_r1_bn1/offset:0\n",
      "generatorA2B/g_r1_c2/Conv/weights:0\n",
      "generatorA2B/g_r1_bn2/scale:0\n",
      "generatorA2B/g_r1_bn2/offset:0\n",
      "generatorA2B/g_r2_c1/Conv/weights:0\n",
      "generatorA2B/g_r2_bn1/scale:0\n",
      "generatorA2B/g_r2_bn1/offset:0\n",
      "generatorA2B/g_r2_c2/Conv/weights:0\n",
      "generatorA2B/g_r2_bn2/scale:0\n",
      "generatorA2B/g_r2_bn2/offset:0\n",
      "generatorA2B/g_r3_c1/Conv/weights:0\n",
      "generatorA2B/g_r3_bn1/scale:0\n",
      "generatorA2B/g_r3_bn1/offset:0\n",
      "generatorA2B/g_r3_c2/Conv/weights:0\n",
      "generatorA2B/g_r3_bn2/scale:0\n",
      "generatorA2B/g_r3_bn2/offset:0\n",
      "generatorA2B/g_r4_c1/Conv/weights:0\n",
      "generatorA2B/g_r4_bn1/scale:0\n",
      "generatorA2B/g_r4_bn1/offset:0\n",
      "generatorA2B/g_r4_c2/Conv/weights:0\n",
      "generatorA2B/g_r4_bn2/scale:0\n",
      "generatorA2B/g_r4_bn2/offset:0\n",
      "generatorA2B/g_r5_c1/Conv/weights:0\n",
      "generatorA2B/g_r5_bn1/scale:0\n",
      "generatorA2B/g_r5_bn1/offset:0\n",
      "generatorA2B/g_r5_c2/Conv/weights:0\n",
      "generatorA2B/g_r5_bn2/scale:0\n",
      "generatorA2B/g_r5_bn2/offset:0\n",
      "generatorA2B/g_r6_c1/Conv/weights:0\n",
      "generatorA2B/g_r6_bn1/scale:0\n",
      "generatorA2B/g_r6_bn1/offset:0\n",
      "generatorA2B/g_r6_c2/Conv/weights:0\n",
      "generatorA2B/g_r6_bn2/scale:0\n",
      "generatorA2B/g_r6_bn2/offset:0\n",
      "generatorA2B/g_r7_c1/Conv/weights:0\n",
      "generatorA2B/g_r7_bn1/scale:0\n",
      "generatorA2B/g_r7_bn1/offset:0\n",
      "generatorA2B/g_r7_c2/Conv/weights:0\n",
      "generatorA2B/g_r7_bn2/scale:0\n",
      "generatorA2B/g_r7_bn2/offset:0\n",
      "generatorA2B/g_r8_c1/Conv/weights:0\n",
      "generatorA2B/g_r8_bn1/scale:0\n",
      "generatorA2B/g_r8_bn1/offset:0\n",
      "generatorA2B/g_r8_c2/Conv/weights:0\n",
      "generatorA2B/g_r8_bn2/scale:0\n",
      "generatorA2B/g_r8_bn2/offset:0\n",
      "generatorA2B/g_r9_c1/Conv/weights:0\n",
      "generatorA2B/g_r9_bn1/scale:0\n",
      "generatorA2B/g_r9_bn1/offset:0\n",
      "generatorA2B/g_r9_c2/Conv/weights:0\n",
      "generatorA2B/g_r9_bn2/scale:0\n",
      "generatorA2B/g_r9_bn2/offset:0\n",
      "generatorA2B/g_d1_dc/Conv2d_transpose/weights:0\n",
      "generatorA2B/g_d1_bn/scale:0\n",
      "generatorA2B/g_d1_bn/offset:0\n",
      "generatorA2B/g_d2_dc/Conv2d_transpose/weights:0\n",
      "generatorA2B/g_d2_bn/scale:0\n",
      "generatorA2B/g_d2_bn/offset:0\n",
      "generatorA2B/g_pred_c/Conv/weights:0\n",
      "generatorB2A/g_e1_c/Conv/weights:0\n",
      "generatorB2A/g_e1_bn/scale:0\n",
      "generatorB2A/g_e1_bn/offset:0\n",
      "generatorB2A/g_e2_c/Conv/weights:0\n",
      "generatorB2A/g_e2_bn/scale:0\n",
      "generatorB2A/g_e2_bn/offset:0\n",
      "generatorB2A/g_e3_c/Conv/weights:0\n",
      "generatorB2A/g_e3_bn/scale:0\n",
      "generatorB2A/g_e3_bn/offset:0\n",
      "generatorB2A/g_r1_c1/Conv/weights:0\n",
      "generatorB2A/g_r1_bn1/scale:0\n",
      "generatorB2A/g_r1_bn1/offset:0\n",
      "generatorB2A/g_r1_c2/Conv/weights:0\n",
      "generatorB2A/g_r1_bn2/scale:0\n",
      "generatorB2A/g_r1_bn2/offset:0\n",
      "generatorB2A/g_r2_c1/Conv/weights:0\n",
      "generatorB2A/g_r2_bn1/scale:0\n",
      "generatorB2A/g_r2_bn1/offset:0\n",
      "generatorB2A/g_r2_c2/Conv/weights:0\n",
      "generatorB2A/g_r2_bn2/scale:0\n",
      "generatorB2A/g_r2_bn2/offset:0\n",
      "generatorB2A/g_r3_c1/Conv/weights:0\n",
      "generatorB2A/g_r3_bn1/scale:0\n",
      "generatorB2A/g_r3_bn1/offset:0\n",
      "generatorB2A/g_r3_c2/Conv/weights:0\n",
      "generatorB2A/g_r3_bn2/scale:0\n",
      "generatorB2A/g_r3_bn2/offset:0\n",
      "generatorB2A/g_r4_c1/Conv/weights:0\n",
      "generatorB2A/g_r4_bn1/scale:0\n",
      "generatorB2A/g_r4_bn1/offset:0\n",
      "generatorB2A/g_r4_c2/Conv/weights:0\n",
      "generatorB2A/g_r4_bn2/scale:0\n",
      "generatorB2A/g_r4_bn2/offset:0\n",
      "generatorB2A/g_r5_c1/Conv/weights:0\n",
      "generatorB2A/g_r5_bn1/scale:0\n",
      "generatorB2A/g_r5_bn1/offset:0\n",
      "generatorB2A/g_r5_c2/Conv/weights:0\n",
      "generatorB2A/g_r5_bn2/scale:0\n",
      "generatorB2A/g_r5_bn2/offset:0\n",
      "generatorB2A/g_r6_c1/Conv/weights:0\n",
      "generatorB2A/g_r6_bn1/scale:0\n",
      "generatorB2A/g_r6_bn1/offset:0\n",
      "generatorB2A/g_r6_c2/Conv/weights:0\n",
      "generatorB2A/g_r6_bn2/scale:0\n",
      "generatorB2A/g_r6_bn2/offset:0\n",
      "generatorB2A/g_r7_c1/Conv/weights:0\n",
      "generatorB2A/g_r7_bn1/scale:0\n",
      "generatorB2A/g_r7_bn1/offset:0\n",
      "generatorB2A/g_r7_c2/Conv/weights:0\n",
      "generatorB2A/g_r7_bn2/scale:0\n",
      "generatorB2A/g_r7_bn2/offset:0\n",
      "generatorB2A/g_r8_c1/Conv/weights:0\n",
      "generatorB2A/g_r8_bn1/scale:0\n",
      "generatorB2A/g_r8_bn1/offset:0\n",
      "generatorB2A/g_r8_c2/Conv/weights:0\n",
      "generatorB2A/g_r8_bn2/scale:0\n",
      "generatorB2A/g_r8_bn2/offset:0\n",
      "generatorB2A/g_r9_c1/Conv/weights:0\n",
      "generatorB2A/g_r9_bn1/scale:0\n",
      "generatorB2A/g_r9_bn1/offset:0\n",
      "generatorB2A/g_r9_c2/Conv/weights:0\n",
      "generatorB2A/g_r9_bn2/scale:0\n",
      "generatorB2A/g_r9_bn2/offset:0\n",
      "generatorB2A/g_d1_dc/Conv2d_transpose/weights:0\n",
      "generatorB2A/g_d1_bn/scale:0\n",
      "generatorB2A/g_d1_bn/offset:0\n",
      "generatorB2A/g_d2_dc/Conv2d_transpose/weights:0\n",
      "generatorB2A/g_d2_bn/scale:0\n",
      "generatorB2A/g_d2_bn/offset:0\n",
      "generatorB2A/g_pred_c/Conv/weights:0\n",
      "discriminatorB/d_h0_conv/Conv/weights:0\n",
      "discriminatorB/d_h1_conv/Conv/weights:0\n",
      "discriminatorB/d_bn1/scale:0\n",
      "discriminatorB/d_bn1/offset:0\n",
      "discriminatorB/d_h2_conv/Conv/weights:0\n",
      "discriminatorB/d_bn2/scale:0\n",
      "discriminatorB/d_bn2/offset:0\n",
      "discriminatorB/d_h3_conv/Conv/weights:0\n",
      "discriminatorB/d_bn3/scale:0\n",
      "discriminatorB/d_bn3/offset:0\n",
      "discriminatorB/d_h3_pred/Conv/weights:0\n",
      "discriminatorA/d_h0_conv/Conv/weights:0\n",
      "discriminatorA/d_h1_conv/Conv/weights:0\n",
      "discriminatorA/d_bn1/scale:0\n",
      "discriminatorA/d_bn1/offset:0\n",
      "discriminatorA/d_h2_conv/Conv/weights:0\n",
      "discriminatorA/d_bn2/scale:0\n",
      "discriminatorA/d_bn2/offset:0\n",
      "discriminatorA/d_h3_conv/Conv/weights:0\n",
      "discriminatorA/d_bn3/scale:0\n",
      "discriminatorA/d_bn3/offset:0\n",
      "discriminatorA/d_h3_pred/Conv/weights:0\n"
     ]
    }
   ],
   "source": [
    "# def main(_):\n",
    "#     if not os.path.exists(args.checkpoint_dir):\n",
    "#         os.makedirs(args.checkpoint_dir)\n",
    "#     if not os.path.exists(args.sample_dir):\n",
    "#         os.makedirs(args.sample_dir)\n",
    "#     if not os.path.exists(args.test_dir):\n",
    "#         os.makedirs(args.test_dir)\n",
    "\n",
    "from module import *\n",
    "from utils import *\n",
    "from collections import namedtuple\n",
    "\n",
    "tfconfig = tf.ConfigProto(allow_soft_placement=True)\n",
    "tfconfig.gpu_options.allow_growth = True\n",
    "\n",
    "with tf.Session(config=tfconfig) as sess:\n",
    "    #model = cyclegan(sess, args)\n",
    "    \n",
    "    # self.sess = sess\n",
    "    # self.batch_size = args.batch_size\n",
    "    # self.image_size = args.fine_size\n",
    "    # self.input_c_dim = args.input_nc\n",
    "    # self.output_c_dim = args.output_nc\n",
    "    # self.L1_lambda = args.L1_lambda\n",
    "    # self.dataset_dir = args.dataset_dir\n",
    "\n",
    "    discriminator = discriminator\n",
    "    generator = generator_resnet # generator_unet\n",
    "    criterionGAN = mae_criterion # abs_criterion\n",
    "\n",
    "    OPTIONS = namedtuple('OPTIONS', 'batch_size image_size gf_dim df_dim output_c_dim ')\n",
    "    options = OPTIONS._make((batch_size,input_height,ngf,ndf,output_nc))\n",
    "\n",
    "    #### Start of building the model ####\n",
    "    real_data = tf.placeholder(tf.float32,[None, input_height, input_width,\n",
    "                                         input_nc + output_nc],name='real_A_and_B_images')\n",
    "\n",
    "    real_A = real_data[:, :, :, :input_nc]\n",
    "    real_B = real_data[:, :, :, input_nc:input_nc + output_nc]\n",
    "\n",
    "    fake_B = generator(real_A, options, False, name=\"generatorA2B\")\n",
    "    fake_A_ = generator(fake_B, options, False, name=\"generatorB2A\")\n",
    "    fake_A = generator(real_B, options, True, name=\"generatorB2A\")\n",
    "    fake_B_ = generator(fake_A, options, True, name=\"generatorA2B\")\n",
    "\n",
    "    DB_fake = discriminator(fake_B, options, reuse=False, name=\"discriminatorB\")\n",
    "    DA_fake = discriminator(fake_A, options, reuse=False, name=\"discriminatorA\")\n",
    "    \n",
    "    g_loss_a2b = criterionGAN(DB_fake, tf.ones_like(DB_fake)) \\\n",
    "                + L1_lambda * abs_criterion(real_A, fake_A_) + L1_lambda * abs_criterion(real_B, fake_B_)\n",
    "    g_loss_b2a = criterionGAN(DA_fake, tf.ones_like(DA_fake)) \\\n",
    "                + L1_lambda * abs_criterion(real_A, fake_A_) + L1_lambda * abs_criterion(real_B, fake_B_)\n",
    "    g_loss = criterionGAN(DA_fake, tf.ones_like(DA_fake)) + criterionGAN(DB_fake, tf.ones_like(DB_fake)) \\\n",
    "                + L1_lambda * abs_criterion(real_A, fake_A_) + L1_lambda * abs_criterion(real_B, fake_B_)\n",
    "\n",
    "    fake_A_sample = tf.placeholder(tf.float32,[None, input_height, input_width, input_nc], name='fake_A_sample')\n",
    "    fake_B_sample = tf.placeholder(tf.float32,[None, output_height, output_width, output_nc], name='fake_B_sample')\n",
    "    \n",
    "    DB_real = discriminator(real_B, options, reuse=True, name=\"discriminatorB\")\n",
    "    DA_real = discriminator(real_A, options, reuse=True, name=\"discriminatorA\")\n",
    "    DB_fake_sample = discriminator(fake_B_sample, options, reuse=True, name=\"discriminatorB\")\n",
    "    DA_fake_sample = discriminator(fake_A_sample, options, reuse=True, name=\"discriminatorA\")\n",
    "\n",
    "    db_loss_real = criterionGAN(DB_real, tf.ones_like(DB_real))\n",
    "    db_loss_fake = criterionGAN(DB_fake_sample, tf.zeros_like(DB_fake_sample))\n",
    "    db_loss = (db_loss_real + db_loss_fake) / 2\n",
    "    \n",
    "    da_loss_real = criterionGAN(DA_real, tf.ones_like(DA_real))\n",
    "    da_loss_fake = criterionGAN(DA_fake_sample, tf.zeros_like(DA_fake_sample))\n",
    "    da_loss = (da_loss_real + da_loss_fake) / 2\n",
    "    \n",
    "    d_loss = da_loss + db_loss\n",
    "\n",
    "    g_loss_a2b_sum = tf.summary.scalar(\"g_loss_a2b\", g_loss_a2b)\n",
    "    g_loss_b2a_sum = tf.summary.scalar(\"g_loss_b2a\", g_loss_b2a)\n",
    "    g_loss_sum = tf.summary.scalar(\"g_loss\", g_loss)\n",
    "    g_sum = tf.summary.merge([g_loss_a2b_sum, g_loss_b2a_sum, g_loss_sum])\n",
    "    \n",
    "    db_loss_sum = tf.summary.scalar(\"db_loss\", db_loss)\n",
    "    da_loss_sum = tf.summary.scalar(\"da_loss\", da_loss)\n",
    "    d_loss_sum = tf.summary.scalar(\"d_loss\", d_loss)\n",
    "    \n",
    "    db_loss_real_sum = tf.summary.scalar(\"db_loss_real\", db_loss_real)\n",
    "    db_loss_fake_sum = tf.summary.scalar(\"db_loss_fake\", db_loss_fake)\n",
    "    \n",
    "    da_loss_real_sum = tf.summary.scalar(\"da_loss_real\", da_loss_real)\n",
    "    da_loss_fake_sum = tf.summary.scalar(\"da_loss_fake\", da_loss_fake)\n",
    "    \n",
    "    d_sum = tf.summary.merge([da_loss_sum, da_loss_real_sum, da_loss_fake_sum,\n",
    "                              db_loss_sum, db_loss_real_sum, db_loss_fake_sum, d_loss_sum])\n",
    "\n",
    "    test_A = tf.placeholder(tf.float32,[None, input_height, input_width, input_nc], name='test_A')\n",
    "    test_B = tf.placeholder(tf.float32,[None, output_height, output_width, output_nc], name='test_B')\n",
    "    \n",
    "    testB = generator(test_A, options, True, name=\"generatorA2B\")\n",
    "    testA = generator(test_B, options, True, name=\"generatorB2A\")\n",
    "\n",
    "    t_vars = tf.trainable_variables()\n",
    "    d_vars = [var for var in t_vars if 'discriminator' in var.name]\n",
    "    g_vars = [var for var in t_vars if 'generator' in var.name]\n",
    "    for var in t_vars: print(var.name)\n",
    "            \n",
    "            \n",
    "    saver = tf.train.Saver()\n",
    "    pool = ImagePool(max_pool)\n",
    "    \n",
    "    #### Train cyclegan ####\n",
    "    learn_rate = tf.placeholder(tf.float32, None, name='learning_rate')\n",
    "    d_optim = tf.train.AdamOptimizer(learn_rate, beta1).minimize(d_loss, var_list=d_vars)\n",
    "    g_optim = tf.train.AdamOptimizer(learn_rate, beta1).minimize(g_loss, var_list=g_vars)\n",
    "\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    writer = tf.summary.FileWriter(\"./logs\", sess.graph)\n",
    "\n",
    "    counter = 1\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(epoches):\n",
    "        \n",
    "        dataA = glob('./datasets/{}/*.*'.format(dataset_dir + '/trainA'))\n",
    "        dataB = glob('./datasets/{}/*.*'.format(dataset_dir + '/trainB'))\n",
    "        np.random.shuffle(dataA)\n",
    "        np.random.shuffle(dataB)\n",
    "        \n",
    "        batch_idxs = min(len(dataA), len(dataB)) // batch_size\n",
    "        lr = init_learn_rate if epoch < epoch_step else init_learn_rate*(epoches-epoch)/(epoches-epoch_step)\n",
    "\n",
    "        for idx in range(0, batch_idxs):\n",
    "            batch_files = list(zip(dataA[idx * batch_size:(idx + 1) * batch_size],\n",
    "                                   dataB[idx * batch_size:(idx + 1) * batch_size]))\n",
    "            batch_images = [load_train_data(batch_file, 286, 256) for batch_file in batch_files]\n",
    "            batch_images = np.array(batch_images).astype(np.float32)\n",
    "\n",
    "            # Update G network and record fake outputs\n",
    "            fake_A, fake_B, _, summary_str = sess.run([fake_A, fake_B, g_optim, g_sum], \n",
    "                                                      feed_dict={real_data: batch_images, learn_rate: lr})\n",
    "            writer.add_summary(summary_str, counter)\n",
    "            [fake_A, fake_B] = pool([fake_A, fake_B])\n",
    "\n",
    "            # Update D network\n",
    "            _, summary_str = sess.run([d_optim, d_sum],feed_dict={real_data: batch_images, fake_A_sample: fake_A,\n",
    "                                       fake_B_sample: fake_B, learn_rate: lr})\n",
    "            writer.add_summary(summary_str, counter)\n",
    "\n",
    "            counter += 1\n",
    "            print((\"Epoch: [%2d] [%4d/%4d] time: %4.4f\" % (\n",
    "                epoch, idx, batch_idxs, time.time() - start_time)))\n",
    "\n",
    "            if np.mod(counter, print_freq) == 1:\n",
    "                sample_model(sample_dir, epoch, idx)\n",
    "\n",
    "            if np.mod(counter, save_freq) == 2:\n",
    "                save(checkpoint_dir, counter)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
