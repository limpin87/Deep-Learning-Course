{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# from sutils import *\n",
    "import os, json\n",
    "from glob import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Dropout, Flatten,Input, BatchNormalization, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n",
      "2.0.8\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for entry in glob('/Data/*'):\n",
    "    print entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(539530, 784)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aircraft_df = pd.DataFrame(np.load('Data/aircraft carrier.npy'))\n",
    "airplane_df = pd.DataFrame(np.load('Data/airplane.npy'))\n",
    "alarm_df = pd.DataFrame(np.load('Data/alarm clock.npy'))\n",
    "ambulance_df = pd.DataFrame(np.load('Data/ambulance.npy'))\n",
    "\n",
    "df_list =  [aircraft_df, airplane_df, alarm_df, ambulance_df]\n",
    "X = pd.concat(df_list)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_target = []\n",
    "for i, df in enumerate(df_list):\n",
    "    labels = np.zeros([df.shape[0],4])\n",
    "    labels[:,i] = 1\n",
    "    if i == 0:\n",
    "        y_target = labels\n",
    "    else:\n",
    "        y_target = np.vstack([y_target,labels])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_target, test_size=0.33, random_state=42)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.values.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.values.reshape(X_test.shape[0],28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Inp = Input(shape=(28,28,1),name = 'Input_layer')\n",
    "\n",
    "#ConvBlock 01\n",
    "conv01 = Conv2D(32, (3, 3), padding='same',activation = 'relu', input_shape=Inp.shape,name = 'Conv01_layer')(Inp)\n",
    "conv02 = Conv2D(32, (3, 3),activation = 'relu',name = 'Conv02_layer')(conv01)\n",
    "maxpool_01 = MaxPooling2D(pool_size=(2, 2),name = 'MaxPool01_layer')(conv02)\n",
    "drop01 = Dropout(0.25,name = 'Dropout01_layer')(maxpool_01)\n",
    "\n",
    "#Convblock 02\n",
    "conv03 = Conv2D(64, (3, 3), padding='same',activation = 'relu',name = 'Conv03_layer')(drop01)\n",
    "conv04 = Conv2D(64, (3, 3),activation = 'relu',name = 'Conv04_layer')(conv03)\n",
    "maxpool_02 = MaxPooling2D(pool_size=(2, 2),name = 'MaxPool02_layer')(conv04)\n",
    "drop02 = Dropout(0.25,name = 'Dropout02_layer')(maxpool_02)\n",
    "\n",
    "# Fully Connected Dense block\n",
    "x = Flatten(name = 'Flatten_layer')(drop02)\n",
    "x = Dense(512, activation='relu',name = 'Dense01_layer')(x)\n",
    "x = Dropout(0.5,name = 'Dropout03_layer')(x)\n",
    "logits_layer = Dense(y_train.shape[1], name= 'logits_layer')(x)\n",
    "output = Activation('softmax',name = 'Sofftmax_layer')(logits_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define model inputs and output\n",
    "model = Model(Inp, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input_layer (InputLayer)     (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "Conv01_layer (Conv2D)        (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "Conv02_layer (Conv2D)        (None, 26, 26, 32)        9248      \n",
      "_________________________________________________________________\n",
      "MaxPool01_layer (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "Dropout01_layer (Dropout)    (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "Conv03_layer (Conv2D)        (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "Conv04_layer (Conv2D)        (None, 11, 11, 64)        36928     \n",
      "_________________________________________________________________\n",
      "MaxPool02_layer (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "Dropout02_layer (Dropout)    (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "Flatten_layer (Flatten)      (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "Dense01_layer (Dense)        (None, 512)               819712    \n",
      "_________________________________________________________________\n",
      "Dropout03_layer (Dropout)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "logits_layer (Dense)         (None, 4)                 2052      \n",
      "_________________________________________________________________\n",
      "Sofftmax_layer (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 886,756\n",
      "Trainable params: 886,756\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real-time data augmentation.\n"
     ]
    }
   ],
   "source": [
    "print('Using real-time data augmentation.')\n",
    "# This will do preprocessing and realtime data augmentation:\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=30,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=True,  # randomly flip images\n",
    "    vertical_flip=False)  # randomly flip images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute quantities required for feature-wise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied).\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 50\n",
    "data_augmentation = True\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'cifar10_simple_CNN.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "11296/11296 [==============================] - 1912s - loss: 0.5124 - acc: 0.8083 - val_loss: 0.3108 - val_acc: 0.8894\n",
      "Epoch 2/50\n",
      "11296/11296 [==============================] - 2071s - loss: 0.3616 - acc: 0.8711 - val_loss: 0.2765 - val_acc: 0.9025\n",
      "Epoch 3/50\n",
      "11296/11296 [==============================] - 2104s - loss: 0.3388 - acc: 0.8799 - val_loss: 0.2667 - val_acc: 0.9058\n",
      "Epoch 4/50\n",
      "11296/11296 [==============================] - 2099s - loss: 0.3341 - acc: 0.8821 - val_loss: 0.2696 - val_acc: 0.9047\n",
      "Epoch 5/50\n",
      "11296/11296 [==============================] - 2100s - loss: 0.3340 - acc: 0.8828 - val_loss: 0.2696 - val_acc: 0.9055\n",
      "Epoch 6/50\n",
      "11296/11296 [==============================] - 2108s - loss: 0.3347 - acc: 0.8823 - val_loss: 0.2856 - val_acc: 0.9064\n",
      "Epoch 7/50\n",
      "11296/11296 [==============================] - 2094s - loss: 0.3352 - acc: 0.8820 - val_loss: 0.2749 - val_acc: 0.9023\n",
      "Epoch 8/50\n",
      "11296/11296 [==============================] - 2095s - loss: 0.3366 - acc: 0.8815 - val_loss: 0.2803 - val_acc: 0.9010\n",
      "Epoch 9/50\n",
      "11296/11296 [==============================] - 2084s - loss: 0.3410 - acc: 0.8812 - val_loss: 0.2805 - val_acc: 0.9093\n",
      "Epoch 10/50\n",
      "11296/11296 [==============================] - 2079s - loss: 0.3416 - acc: 0.8810 - val_loss: 0.2656 - val_acc: 0.9066\n",
      "Epoch 11/50\n",
      "11296/11296 [==============================] - 2098s - loss: 0.3449 - acc: 0.8807 - val_loss: 0.2751 - val_acc: 0.9028\n",
      "Epoch 12/50\n",
      "11296/11296 [==============================] - 2097s - loss: 0.3487 - acc: 0.8798 - val_loss: 0.2594 - val_acc: 0.9067\n",
      "Epoch 13/50\n",
      "11296/11296 [==============================] - 2093s - loss: 0.3494 - acc: 0.8792 - val_loss: 0.2658 - val_acc: 0.9092\n",
      "Epoch 14/50\n",
      "11296/11296 [==============================] - 2113s - loss: 0.3552 - acc: 0.8777 - val_loss: 0.2551 - val_acc: 0.9083\n",
      "Epoch 15/50\n",
      "11296/11296 [==============================] - 2114s - loss: 0.3576 - acc: 0.8769 - val_loss: 0.2685 - val_acc: 0.9050\n",
      "Epoch 16/50\n",
      " 6499/11296 [================>.............] - ETA: 819s - loss: 0.3606 - acc: 0.8753"
     ]
    }
   ],
   "source": [
    "hist = model.fit_generator(datagen.flow(X_train, y_train,\n",
    "                                 batch_size=batch_size),\n",
    "                    steps_per_epoch=X_train.shape[0] // batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_train(hist):\n",
    "    h = hist.history\n",
    "    if 'acc' in h:\n",
    "        meas='acc'\n",
    "        loc='lower right'\n",
    "    else:\n",
    "        meas='loss'\n",
    "        loc='upper right'\n",
    "    plt.plot(hist.history[meas])\n",
    "    plt.plot(hist.history['val_'+meas])\n",
    "    plt.title('model '+meas)\n",
    "    plt.ylabel(meas)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc=loc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_train(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
