{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Style-transfer Notebook:\n",
    "\n",
    "This notebook implements style transfer by optimizing the input image to fit the styles of the output image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disclaimer:\n",
    "This notebook is based heavily on the style-transfer tutorial provided \n",
    "by [Magnus Erik Hvass Pedersen](http://www.hvass-labs.org/)\n",
    "/ [GitHub](https://github.com/Hvass-Labs/TensorFlow-Tutorials) / [Videos on YouTube](https://www.youtube.com/playlist?list=PL9Hr9sNUjfsmEu1ZniY0XpHSzl5uihcXZ)\n",
    "\n",
    "I will be experimenting with different possibilites in this notebook <br />\n",
    "### Major Differences/Change: <br />\n",
    "1. Added visualization of convolutional layers to better understand extracted features (Done)\n",
    "2. Modify to use Keras Pre-trained notebooks\n",
    "3. Modify to use BFGS to optimize the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Loading the necessary libraries\n",
    "from IPython.display import Image, display\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "\n",
    "import keras\n",
    "# inception_resnet_v2 import InceptionResNetV2\n",
    "from Utilities import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n",
      "2.0.8\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading VGG16 Model ...\n",
      "Data has apparently already been downloaded and unpacked.\n"
     ]
    }
   ],
   "source": [
    "## Loading a pre-trained Deep-Neural Network\n",
    "import vgg16\n",
    "vgg16.maybe_download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = vgg16.VGG16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_filename = 'images/buildings300.jpg'\n",
    "content_image = load_image(content_filename, max_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'conv3_1/conv3_1:0' shape=(?, ?, ?, 256) dtype=float32>]\n",
      "[array([[[[  1.32632375e+05,   0.00000000e+00,   2.74465850e+06, ...,\n",
      "            1.15579531e+05,   8.54722812e+04,   1.73833109e+05],\n",
      "         [  1.54653250e+05,   5.69748633e+04,   2.02821275e+06, ...,\n",
      "            2.57277672e+05,   1.50330297e+05,   2.13523922e+05],\n",
      "         [  1.26705594e+05,   9.95901094e+04,   1.84908812e+06, ...,\n",
      "            2.38215688e+05,   1.21095422e+05,   1.37134094e+05],\n",
      "         ..., \n",
      "         [  0.00000000e+00,   2.45659391e+05,   2.12087650e+06, ...,\n",
      "            3.30952375e+05,   1.25636391e+05,   2.46480625e+05],\n",
      "         [  0.00000000e+00,   8.22199219e+04,   2.44590950e+06, ...,\n",
      "            2.26619859e+05,   1.08377094e+05,   2.41334594e+05],\n",
      "         [  3.58366992e+04,   0.00000000e+00,   3.38378475e+06, ...,\n",
      "            6.64151250e+04,   1.01604359e+05,   2.40363328e+05]],\n",
      "\n",
      "        [[  3.71896172e+04,   2.62783188e+05,   1.86328975e+06, ...,\n",
      "            0.00000000e+00,   1.10429016e+05,   3.17481312e+05],\n",
      "         [  0.00000000e+00,   3.27856688e+05,   0.00000000e+00, ...,\n",
      "            0.00000000e+00,   1.46725234e+05,   3.58785688e+05],\n",
      "         [  0.00000000e+00,   3.19237969e+05,   0.00000000e+00, ...,\n",
      "            3.48089766e+04,   1.45748031e+05,   2.10299328e+05],\n",
      "         ..., \n",
      "         [  0.00000000e+00,   4.02935594e+05,   9.19209277e+03, ...,\n",
      "            6.23791484e+04,   9.77792734e+04,   3.22892875e+05],\n",
      "         [  0.00000000e+00,   3.86511312e+05,   1.55593594e+05, ...,\n",
      "            3.12589668e+04,   9.55503594e+04,   4.07296656e+05],\n",
      "         [  0.00000000e+00,   2.90746594e+05,   2.46759825e+06, ...,\n",
      "            8.55436641e+04,   3.64393750e+04,   4.31289875e+05]],\n",
      "\n",
      "        [[  2.86707559e+04,   1.68240188e+05,   1.91944138e+06, ...,\n",
      "            7.54454766e+04,   1.35636500e+05,   2.06782562e+05],\n",
      "         [  2.31946914e+04,   2.05171922e+05,   0.00000000e+00, ...,\n",
      "            1.20492477e+05,   1.23916141e+05,   2.21035875e+05],\n",
      "         [  6.36711719e+04,   2.25241484e+05,   0.00000000e+00, ...,\n",
      "            1.56355922e+05,   8.65770781e+04,   1.18604453e+05],\n",
      "         ..., \n",
      "         [  0.00000000e+00,   2.94397406e+05,   0.00000000e+00, ...,\n",
      "            5.93099961e+04,   6.00742031e+04,   1.81792234e+05],\n",
      "         [  0.00000000e+00,   2.81667531e+05,   0.00000000e+00, ...,\n",
      "            3.03434219e+04,   9.13787344e+04,   2.44780609e+05],\n",
      "         [  0.00000000e+00,   2.30541547e+05,   2.26188050e+06, ...,\n",
      "            6.59777812e+04,   5.44252695e+04,   3.11351531e+05]],\n",
      "\n",
      "        ..., \n",
      "        [[  9.13287500e+04,   0.00000000e+00,   5.89522250e+05, ...,\n",
      "            1.64862156e+05,   1.11012280e+03,   0.00000000e+00],\n",
      "         [  9.82105078e+04,   0.00000000e+00,   0.00000000e+00, ...,\n",
      "            1.18447672e+05,   0.00000000e+00,   0.00000000e+00],\n",
      "         [  2.74941688e+05,   0.00000000e+00,   0.00000000e+00, ...,\n",
      "            1.15223992e+05,   0.00000000e+00,   0.00000000e+00],\n",
      "         ..., \n",
      "         [  1.72479562e+05,   0.00000000e+00,   0.00000000e+00, ...,\n",
      "            1.40362422e+05,   1.25212008e+05,   0.00000000e+00],\n",
      "         [  2.77628344e+05,   0.00000000e+00,   5.98170781e+04, ...,\n",
      "            0.00000000e+00,   2.70112844e+05,   0.00000000e+00],\n",
      "         [  0.00000000e+00,   0.00000000e+00,   1.73673050e+06, ...,\n",
      "            0.00000000e+00,   2.73038031e+05,   7.62007500e+04]],\n",
      "\n",
      "        [[  1.66064203e+05,   0.00000000e+00,   7.53055875e+05, ...,\n",
      "            1.02913562e+05,   0.00000000e+00,   1.85716797e+04],\n",
      "         [  1.50603875e+05,   0.00000000e+00,   0.00000000e+00, ...,\n",
      "            2.56473242e+04,   0.00000000e+00,   7.12655127e+03],\n",
      "         [  2.54586609e+05,   0.00000000e+00,   0.00000000e+00, ...,\n",
      "            7.66666875e+04,   0.00000000e+00,   0.00000000e+00],\n",
      "         ..., \n",
      "         [  5.40772812e+05,   0.00000000e+00,   0.00000000e+00, ...,\n",
      "            1.53912719e+05,   4.42110078e+04,   0.00000000e+00],\n",
      "         [  3.86772688e+05,   0.00000000e+00,   9.83776855e+03, ...,\n",
      "            0.00000000e+00,   1.34056594e+05,   0.00000000e+00],\n",
      "         [  0.00000000e+00,   0.00000000e+00,   1.63897775e+06, ...,\n",
      "            1.21686973e+04,   1.67011047e+05,   8.93414688e+04]],\n",
      "\n",
      "        [[  8.31646484e+04,   2.37975039e+04,   1.11867000e+06, ...,\n",
      "            1.05759250e+05,   0.00000000e+00,   5.65281836e+04],\n",
      "         [  0.00000000e+00,   1.15685244e+04,   7.87999125e+05, ...,\n",
      "            1.07716234e+05,   0.00000000e+00,   7.22896484e+04],\n",
      "         [  1.42763891e+05,   5.94142383e+04,   6.96434688e+05, ...,\n",
      "            1.47992609e+05,   0.00000000e+00,   5.63693477e+04],\n",
      "         ..., \n",
      "         [  4.69250500e+05,   1.71232453e+05,   9.89953125e+05, ...,\n",
      "            1.42629406e+05,   9.60966719e+04,   6.29602852e+04],\n",
      "         [  2.60387938e+05,   6.58565918e+02,   1.69316975e+06, ...,\n",
      "            3.07000406e+05,   6.30308242e+04,   2.78552344e+04],\n",
      "         [  0.00000000e+00,   0.00000000e+00,   2.57006475e+06, ...,\n",
      "            3.40581375e+05,   0.00000000e+00,   3.32324062e+04]]]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "session = tf.InteractiveSession(graph=model.graph)\n",
    "feed_dict = model.create_feed_dict(image=content_image)\n",
    "layers = model.get_layer_tensors([4])\n",
    "print layers\n",
    "# Calculate the output values of those layers when\n",
    "# feeding the content-image to the model.\n",
    "values = session.run(layers, feed_dict=feed_dict)\n",
    "print values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'layer_ids' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-57bac4ea4920>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Get references to the tensors for the given layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mlayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Calculate the output values of those layers when\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'layer_ids' is not defined"
     ]
    }
   ],
   "source": [
    "ession = tf.InteractiveSession(graph=model.graph)\n",
    "# Create a feed-dict with the content-image.\n",
    "feed_dict = model.create_feed_dict(image=content_image)\n",
    "\n",
    "# Get references to the tensors for the given layers.\n",
    "layers = model.get_layer_tensors(layer_ids)\n",
    "\n",
    "# Calculate the output values of those layers when\n",
    "# feeding the content-image to the model.\n",
    "values = session.run(layers, feed_dict=feed_dict)\n",
    "\n",
    "# Set the model's graph as the default so we can add\n",
    "# computational nodes to it. It is not always clear\n",
    "# when this is necessary in TensorFlow, but if you\n",
    "# want to re-use this code then it may be necessary.\n",
    "with model.graph.as_default():\n",
    "    # Initialize an empty list of loss-functions.\n",
    "    layer_losses = []\n",
    "\n",
    "    # For each layer and its corresponding values\n",
    "    # for the content-image.\n",
    "    for value, layer in zip(values, layers):\n",
    "        # These are the values that are calculated\n",
    "        # for this layer in the model when inputting\n",
    "        # the content-image. Wrap it to ensure it\n",
    "        # is a const - although this may be done\n",
    "        # automatically by TensorFlow.\n",
    "        value_const = tf.constant(value)\n",
    "\n",
    "        # The loss-function for this layer is the\n",
    "        # Mean Squared Error between the layer-values\n",
    "        # when inputting the content- and mixed-images.\n",
    "        # Note that the mixed-image is not calculated\n",
    "        # yet, we are merely creating the operations\n",
    "        # for calculating the MSE between those two.\n",
    "        loss = mean_squared_error(layer, value_const)\n",
    "\n",
    "        # Add the loss-function for this layer to the\n",
    "        # list of loss-functions.\n",
    "        layer_losses.append(loss)\n",
    "\n",
    "    # The combined loss for all layers is just the average.\n",
    "    # The loss-functions could be weighted differently for\n",
    "    # each layer. You can try it and see what happens.\n",
    "    total_loss = tf.reduce_mean(layer_losses)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def style_transfer(model, session, content_image, style_image,\n",
    "                   content_layer_ids, style_layer_ids,\n",
    "                   weight_content=1.5, weight_style=10.0,\n",
    "                   weight_denoise=0.3,\n",
    "                   num_iterations=120, step_size=10.0):\n",
    "\n",
    "#     model = vgg16.VGG16()\n",
    "\n",
    "#     # Create a TensorFlow-session.\n",
    "#     session = tf.InteractiveSession(graph=model.graph)\n",
    "\n",
    "#     # Print the names of the content-layers.\n",
    "#     print(\"Content layers:\")\n",
    "#     print(model.get_layer_names(content_layer_ids))\n",
    "#     print()\n",
    "\n",
    "#     visualize_layers(session,model,content_image,content_layer_ids)\n",
    "    \n",
    "#     # Print the names of the style-layers.\n",
    "#     print(\"Style layers:\")\n",
    "#     print(model.get_layer_names(style_layer_ids))\n",
    "#     print()\n",
    "    \n",
    "#     visualize_layers(session,model,style_image,style_layer_ids)\n",
    "\n",
    "    # Create the loss-function for the content-layers and -image.\n",
    "    loss_content = create_content_loss(session=session,\n",
    "                                       model=model,\n",
    "                                       content_image=content_image,\n",
    "                                       layer_ids=content_layer_ids)\n",
    "\n",
    "    # Create the loss-function for the style-layers and -image.\n",
    "    loss_style = create_style_loss(session=session,\n",
    "                                   model=model,\n",
    "                                   style_image=style_image,\n",
    "                                   layer_ids=style_layer_ids)    \n",
    "\n",
    "    # Create the loss-function for the denoising of the mixed-image.\n",
    "    loss_denoise = create_denoise_loss(model)\n",
    "\n",
    "    # Create TensorFlow variables for adjusting the values of\n",
    "    # the loss-functions. This is explained below.\n",
    "    adj_content = tf.Variable(1e-10, name='adj_content')\n",
    "    adj_style = tf.Variable(1e-10, name='adj_style')\n",
    "    adj_denoise = tf.Variable(1e-10, name='adj_denoise')\n",
    "\n",
    "    # Initialize the adjustment values for the loss-functions.\n",
    "    session.run([adj_content.initializer,\n",
    "                 adj_style.initializer,\n",
    "                 adj_denoise.initializer])\n",
    "\n",
    "    # Create TensorFlow operations for updating the adjustment values.\n",
    "    # These are basically just the reciprocal values of the\n",
    "    # loss-functions, with a small value 1e-10 added to avoid the\n",
    "    # possibility of division by zero.\n",
    "    update_adj_content = adj_content.assign(1.0 / (loss_content + 1e-10))\n",
    "    update_adj_style = adj_style.assign(1.0 / (loss_style + 1e-10))\n",
    "    update_adj_denoise = adj_denoise.assign(1.0 / (loss_denoise + 1e-10))\n",
    "\n",
    "    # This is the weighted loss-function that we will minimize\n",
    "    # below in order to generate the mixed-image.\n",
    "    # Because we multiply the loss-values with their reciprocal\n",
    "    # adjustment values, we can use relative weights for the\n",
    "    # loss-functions that are easier to select, as they are\n",
    "    # independent of the exact choice of style- and content-layers.\n",
    "    loss_combined = weight_content * adj_content * loss_content + \\\n",
    "                    weight_style * adj_style * loss_style + \\\n",
    "                    weight_denoise * adj_denoise * loss_denoise\n",
    "\n",
    "    # Use TensorFlow to get the mathematical function for the\n",
    "    # gradient of the combined loss-function with regard to\n",
    "    # the input image.\n",
    "    gradient = tf.gradients(loss_combined, model.input)\n",
    "\n",
    "    # List of tensors that we will run in each optimization iteration.\n",
    "    run_list = [gradient, update_adj_content, update_adj_style, \\\n",
    "                update_adj_denoise]\n",
    "\n",
    "    # The mixed-image is initialized with random noise.\n",
    "    # It is the same size as the content-image.\n",
    "    mixed_image = np.random.rand(*content_image.shape) + 128\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        # Create a feed-dict with the mixed-image.\n",
    "        feed_dict = model.create_feed_dict(image=mixed_image)\n",
    "\n",
    "        # Use TensorFlow to calculate the value of the\n",
    "        # gradient, as well as updating the adjustment values.\n",
    "        grad, adj_content_val, adj_style_val, adj_denoise_val \\\n",
    "        = session.run(run_list, feed_dict=feed_dict)\n",
    "\n",
    "        # Reduce the dimensionality of the gradient.\n",
    "        grad = np.squeeze(grad)\n",
    "\n",
    "        # Scale the step-size according to the gradient-values.\n",
    "        step_size_scaled = step_size / (np.std(grad) + 1e-8)\n",
    "\n",
    "        # Update the image by following the gradient.\n",
    "        mixed_image -= grad * step_size_scaled\n",
    "\n",
    "        # Ensure the image has valid pixel-values between 0 and 255.\n",
    "        mixed_image = np.clip(mixed_image, 0.0, 255.0)\n",
    "\n",
    "        # Print a little progress-indicator.\n",
    "#         print \". \", end=\"\"\n",
    "\n",
    "        # Display status once every 10 iterations, and the last.\n",
    "        if (i % 10 == 0) or (i == num_iterations - 1):\n",
    "            print()\n",
    "            print(\"Iteration:\", i)\n",
    "\n",
    "            # Print adjustment weights for loss-functions.\n",
    "            msg = \"Weight Adj. for Content: {0:.2e}, Style: {1:.2e}, Denoise: {2:.2e}\"\n",
    "            print(msg.format(adj_content_val, adj_style_val, adj_denoise_val))\n",
    "\n",
    "            # Plot the content-, style- and mixed-images.\n",
    "            plot_images(content_image=content_image,\n",
    "                        style_image=style_image,\n",
    "                        mixed_image=mixed_image)\n",
    "            \n",
    "    print()\n",
    "    print(\"Final image:\")\n",
    "    plot_image_big(mixed_image)\n",
    "\n",
    "    # Close the TensorFlow session to release its resources.\n",
    "    session.close()\n",
    "    \n",
    "    # Return the mixed-image.\n",
    "    return mixed_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start of Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "style_filename = 'images/steampunk.jpg'\n",
    "style_image = load_image(style_filename, max_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The VGG16-model has 13 convolutional layers.\n",
    "# This selects all those layers as the style-layers.\n",
    "# This is somewhat slow to optimize.\n",
    "style_layer_ids = list(range(13))\n",
    "\n",
    "# You can also select a sub-set of the layers, e.g. like this:\n",
    "# style_layer_ids = [1, 2, 3, 4]\n",
    "\n",
    "content_layer_ids = [4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing and controlling the layers used \n",
    "\n",
    "model = vgg16.VGG16()\n",
    "\n",
    "# Create a TensorFlow-session.\n",
    "session = tf.InteractiveSession(graph=model.graph)\n",
    "\n",
    "# Print the names of the content-layers.\n",
    "print(\"Content layers:\")\n",
    "print(model.get_layer_names(content_layer_ids))\n",
    "print()\n",
    "\n",
    "visualize_layers(session,model,content_image,content_layer_ids)\n",
    "\n",
    "# Print the names of the style-layers.\n",
    "print(\"Style layers:\")\n",
    "print(model.get_layer_names(style_layer_ids))\n",
    "print()\n",
    "\n",
    "visualize_layers(session,model,style_image,style_layer_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "img = style_transfer(model, session, content_image=content_image,\n",
    "                     style_image=style_image,\n",
    "                     content_layer_ids=content_layer_ids,\n",
    "                     style_layer_ids=style_layer_ids,\n",
    "                     weight_content=1.5,\n",
    "                     weight_style=10.0,\n",
    "                     weight_denoise=0.3,\n",
    "                     num_iterations=600,\n",
    "                     step_size=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
