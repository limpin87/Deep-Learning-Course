{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os, json\n",
    "from glob import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Dropout, Flatten,Input, BatchNormalization, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.applications.vgg19 import VGG19\n",
    "\n",
    "from keras.callbacks import EarlyStopping,LearningRateScheduler,ReduceLROnPlateau, TensorBoard\n",
    "\n",
    "import multi_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n",
      "2.0.8\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes:  14\n"
     ]
    }
   ],
   "source": [
    "fnames =  glob('/../../nfs/p4/shared/datasets/quick_draw/numpy_bitmap/*') ## Data on server\n",
    "# fnames = glob('Data/*') ## Local data on Zenbook Prime\n",
    "# for entry in fnames:\n",
    "#     print entry\n",
    "print 'Number of classes: ', len(fnames) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "## Creating the training data set\n",
    "Npc = 8000 # Number of images to use for each class \n",
    "Npc_t = 2000  # Number of images to use for testing for each class \n",
    "n_class = 100 # Number of classes to use \n",
    "\n",
    "for i, entry in enumerate(fnames):\n",
    "    print i\n",
    "    if i >= n_class:\n",
    "        break\n",
    "    data = np.load(entry)[:Npc]\n",
    "    labels =  np.zeros([data.shape[0],n_class])\n",
    "    labels[:,i] = 1\n",
    "    if i == 0:\n",
    "        X = data[:Npc]\n",
    "        targets = labels\n",
    "    else:\n",
    "        X = np.vstack([X, data])\n",
    "        targets = np.vstack([targets,labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (5600, 784)\n",
      "Target shape: (5600, 100)\n"
     ]
    }
   ],
   "source": [
    "print 'Input shape:', X.shape\n",
    "print 'Target shape:', targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, targets, test_size=0.33, random_state=42)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0],28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Inp = Input(shape=(28,28,1),name = 'Input_layer')\n",
    "\n",
    "#ConvBlock 01\n",
    "conv01 = Conv2D(64, (5, 5), padding='same',activation = 'relu', input_shape=Inp.shape,name = 'Conv01_layer')(Inp)\n",
    "conv01 = BatchNormalization()(conv01)\n",
    "conv02 = Conv2D(64, (5, 5),activation = 'relu',name = 'Conv02_layer')(conv01)\n",
    "maxpool_01 = MaxPooling2D(pool_size=(2, 2),name = 'MaxPool01_layer')(conv02)\n",
    "drop01 = Dropout(0.25,name = 'Dropout01_layer')(maxpool_01)\n",
    "\n",
    "#Convblock 02\n",
    "conv03 = Conv2D(128, (3, 3), padding='same',activation = 'relu',name = 'Conv03_layer')(drop01)\n",
    "conv03 = BatchNormalization()(conv03)\n",
    "conv04 = Conv2D(128, (3, 3),activation = 'relu',name = 'Conv04_layer')(conv03)\n",
    "maxpool_02 = MaxPooling2D(pool_size=(2, 2),name = 'MaxPool02_layer')(conv04)\n",
    "drop02 = Dropout(0.25,name = 'Dropout02_layer')(maxpool_02)\n",
    "\n",
    "# Fully Connected Dense block\n",
    "x = Flatten(name = 'Flatten_layer')(drop02)\n",
    "x = Dense(512, activation='relu',name = 'Dense01_layer')(x)\n",
    "x = Dropout(0.5,name = 'Dropout03_layer')(x)\n",
    "x = BatchNormalization()(x)\n",
    "logits_layer = Dense(y_train.shape[1], name= 'logits_layer')(x)\n",
    "output = Activation('softmax',name = 'Sofftmax_layer')(logits_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define model inputs and output\n",
    "model = Model(Inp, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input_layer (InputLayer)     (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "Conv01_layer (Conv2D)        (None, 28, 28, 64)        1664      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "Conv02_layer (Conv2D)        (None, 24, 24, 64)        102464    \n",
      "_________________________________________________________________\n",
      "MaxPool01_layer (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "Dropout01_layer (Dropout)    (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "Conv03_layer (Conv2D)        (None, 12, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "Conv04_layer (Conv2D)        (None, 10, 10, 128)       147584    \n",
      "_________________________________________________________________\n",
      "MaxPool02_layer (MaxPooling2 (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "Dropout02_layer (Dropout)    (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "Flatten_layer (Flatten)      (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "Dense01_layer (Dense)        (None, 512)               1638912   \n",
      "_________________________________________________________________\n",
      "Dropout03_layer (Dropout)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "logits_layer (Dense)         (None, 100)               51300     \n",
      "_________________________________________________________________\n",
      "Sofftmax_layer (Activation)  (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 2,018,596\n",
      "Trainable params: 2,017,188\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = multi_gpu.make_parallel(model,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initiate RMSprop optimizer\n",
    "\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# callbacks = [ReduceLROnPlateau(monitor='loss'),\n",
    "#             TensorBoard(log_dir=\"logs/{0}\".format(\"quickdraw_lr0.0001_dc1e-6\"))]\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real-time data augmentation.\n"
     ]
    }
   ],
   "source": [
    "print('Using real-time data augmentation.')\n",
    "# This will do preprocessing and realtime data augmentation:\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=30,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=True,  # randomly flip images\n",
    "    vertical_flip=False)  # randomly flip images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "58/58 [==============================] - 185s - loss: 4.5380 - acc: 0.0853 - val_loss: 4.5136 - val_acc: 0.0871\n",
      "Epoch 2/10\n",
      "58/58 [==============================] - 184s - loss: 3.4170 - acc: 0.2560 - val_loss: 4.8788 - val_acc: 0.1147\n",
      "Epoch 3/10\n",
      "58/58 [==============================] - 126s - loss: 2.9435 - acc: 0.3325 - val_loss: 5.7448 - val_acc: 0.0741\n",
      "Epoch 4/10\n",
      "58/58 [==============================] - 132s - loss: 2.6520 - acc: 0.3694 - val_loss: 6.3537 - val_acc: 0.0801\n",
      "Epoch 5/10\n",
      "58/58 [==============================] - 135s - loss: 2.3689 - acc: 0.4224 - val_loss: 6.5629 - val_acc: 0.1169\n",
      "Epoch 6/10\n",
      "58/58 [==============================] - 132s - loss: 2.1885 - acc: 0.4496 - val_loss: 5.9922 - val_acc: 0.1374\n",
      "Epoch 7/10\n",
      "58/58 [==============================] - 124s - loss: 2.0635 - acc: 0.4682 - val_loss: 5.0556 - val_acc: 0.1499\n",
      "Epoch 8/10\n",
      "58/58 [==============================] - 126s - loss: 1.9567 - acc: 0.4889 - val_loss: 3.9303 - val_acc: 0.2256\n",
      "Epoch 9/10\n",
      "58/58 [==============================] - 137s - loss: 1.8433 - acc: 0.5044 - val_loss: 2.6571 - val_acc: 0.3247\n",
      "Epoch 10/10\n",
      "58/58 [==============================] - 149s - loss: 1.7315 - acc: 0.5343 - val_loss: 2.0635 - val_acc: 0.4226\n"
     ]
    }
   ],
   "source": [
    "# Compute quantities required for feature-wise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied).\n",
    "datagen.fit(X_train)\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "data_augmentation = True\n",
    "# num_predictions = 20\n",
    "\n",
    "hist = model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size),\n",
    "                            steps_per_epoch=X_train.shape[0] // batch_size,\n",
    "                            epochs=epochs,\n",
    "#                             callbacks = callbacks,\n",
    "                            validation_data=(X_test, y_test),\n",
    "                            workers=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start of Image retrival algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.get_layer('Flatten_layer').output\n",
    "transformer = Model(model.inputs, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input_layer (InputLayer)     (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "Conv01_layer (Conv2D)        (None, 28, 28, 64)        1664      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "Conv02_layer (Conv2D)        (None, 24, 24, 64)        102464    \n",
      "_________________________________________________________________\n",
      "MaxPool01_layer (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "Dropout01_layer (Dropout)    (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "Conv03_layer (Conv2D)        (None, 12, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "Conv04_layer (Conv2D)        (None, 10, 10, 128)       147584    \n",
      "_________________________________________________________________\n",
      "MaxPool02_layer (MaxPooling2 (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "Dropout02_layer (Dropout)    (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "Flatten_layer (Flatten)      (None, 3200)              0         \n",
      "=================================================================\n",
      "Total params: 326,336\n",
      "Trainable params: 325,952\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transformer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Vectors = transformer.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_vector = transformer.predict(X_test[0].reshape(1,28,28,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import norm\n",
    "ind = np.argmin(norm(X_Vectors-Y_vector[:,None], axis=1, ord=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMuXwm2Xq/wFJ3V9gogLuRgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f13ba4cd550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nb5Yph98sUw6/Wab+D5gtIJSJ2zvbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f13ba4cd590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = X_test[0].reshape([28,28])*255\n",
    "plt.imshow(img)\n",
    "plt.title('Query Image')\n",
    "plt.show()\n",
    "img = X_train[ind].reshape([28,28])*255\n",
    "plt.imshow(img)\n",
    "plt.title('Best found Image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
