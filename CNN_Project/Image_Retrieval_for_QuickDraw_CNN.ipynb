{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os, json\n",
    "from glob import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Dropout, Flatten,Input, BatchNormalization, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.applications.vgg19 import VGG19\n",
    "\n",
    "from keras.callbacks import EarlyStopping,LearningRateScheduler,ReduceLROnPlateau, TensorBoard\n",
    "\n",
    "import multi_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n",
      "2.0.8\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes:  345\n"
     ]
    }
   ],
   "source": [
    "fnames =  glob('/../../nfs/p4/shared/datasets/quick_draw/numpy_bitmap/*') ## Data on server\n",
    "# fnames = glob('Data/*') ## Local data on Zenbook Prime\n",
    "# for entry in fnames:\n",
    "#     print entry\n",
    "print 'Number of classes: ', len(fnames) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "## Creating the training data set\n",
    "Npc = 8000 # Number of images to use for each class \n",
    "Npc_t = 2000  # Number of images to use for testing for each class \n",
    "n_class = 100 # Number of classes to use \n",
    "\n",
    "for i, entry in enumerate(fnames):\n",
    "    print i\n",
    "    if i >= n_class:\n",
    "        break\n",
    "    data = np.load(entry)[:Npc]\n",
    "    labels =  np.zeros([data.shape[0],n_class])\n",
    "    labels[:,i] = 1\n",
    "    if i == 0:\n",
    "        X = data[:Npc]\n",
    "        targets = labels\n",
    "    else:\n",
    "        X = np.vstack([X, data])\n",
    "        targets = np.vstack([targets,labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (800000, 784)\n",
      "Target shape: (800000, 100)\n"
     ]
    }
   ],
   "source": [
    "print 'Input shape:', X.shape\n",
    "print 'Target shape:', targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, targets, test_size=0.33, random_state=42)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0],28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Inp = Input(shape=(28,28,1),name = 'Input_layer')\n",
    "\n",
    "#ConvBlock 01\n",
    "conv01 = Conv2D(64, (5, 5), padding='same',activation = 'relu', input_shape=Inp.shape,name = 'Conv01_layer')(Inp)\n",
    "conv01 = BatchNormalization()(conv01)\n",
    "conv02 = Conv2D(64, (5, 5),activation = 'relu',name = 'Conv02_layer')(conv01)\n",
    "maxpool_01 = MaxPooling2D(pool_size=(2, 2),name = 'MaxPool01_layer')(conv02)\n",
    "drop01 = Dropout(0.25,name = 'Dropout01_layer')(maxpool_01)\n",
    "\n",
    "#Convblock 02\n",
    "conv03 = Conv2D(128, (3, 3), padding='same',activation = 'relu',name = 'Conv03_layer')(drop01)\n",
    "conv03 = BatchNormalization()(conv03)\n",
    "conv04 = Conv2D(128, (3, 3),activation = 'relu',name = 'Conv04_layer')(conv03)\n",
    "maxpool_02 = MaxPooling2D(pool_size=(2, 2),name = 'MaxPool02_layer')(conv04)\n",
    "drop02 = Dropout(0.25,name = 'Dropout02_layer')(maxpool_02)\n",
    "\n",
    "# Fully Connected Dense block\n",
    "x = Flatten(name = 'Flatten_layer')(drop02)\n",
    "x = Dense(512, activation='relu',name = 'Dense01_layer')(x)\n",
    "x = Dropout(0.5,name = 'Dropout03_layer')(x)\n",
    "x = BatchNormalization()(x)\n",
    "logits_layer = Dense(y_train.shape[1], name= 'logits_layer')(x)\n",
    "output = Activation('softmax',name = 'Sofftmax_layer')(logits_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define model inputs and output\n",
    "model = Model(Inp, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input_layer (InputLayer)     (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "Conv01_layer (Conv2D)        (None, 28, 28, 64)        1664      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "Conv02_layer (Conv2D)        (None, 24, 24, 64)        102464    \n",
      "_________________________________________________________________\n",
      "MaxPool01_layer (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "Dropout01_layer (Dropout)    (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "Conv03_layer (Conv2D)        (None, 12, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "Conv04_layer (Conv2D)        (None, 10, 10, 128)       147584    \n",
      "_________________________________________________________________\n",
      "MaxPool02_layer (MaxPooling2 (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "Dropout02_layer (Dropout)    (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "Flatten_layer (Flatten)      (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "Dense01_layer (Dense)        (None, 512)               1638912   \n",
      "_________________________________________________________________\n",
      "Dropout03_layer (Dropout)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "logits_layer (Dense)         (None, 100)               51300     \n",
      "_________________________________________________________________\n",
      "Sofftmax_layer (Activation)  (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 2,018,596\n",
      "Trainable params: 2,017,188\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = multi_gpu.make_parallel(model,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initiate RMSprop optimizer\n",
    "\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# callbacks = [ReduceLROnPlateau(monitor='loss'),\n",
    "#             TensorBoard(log_dir=\"logs/{0}\".format(\"quickdraw_lr0.0001_dc1e-6\"))]\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real-time data augmentation.\n"
     ]
    }
   ],
   "source": [
    "print('Using real-time data augmentation.')\n",
    "# This will do preprocessing and realtime data augmentation:\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=30,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=True,  # randomly flip images\n",
    "    vertical_flip=False)  # randomly flip images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8375/8375 [==============================] - 423s - loss: 3.0725 - acc: 0.2740 - val_loss: 1.7421 - val_acc: 0.5596\n",
      "Epoch 2/10\n",
      "8375/8375 [==============================] - 413s - loss: 2.1339 - acc: 0.4631 - val_loss: 1.4107 - val_acc: 0.6353\n",
      "Epoch 3/10\n",
      "8375/8375 [==============================] - 379s - loss: 1.8753 - acc: 0.5244 - val_loss: 1.2989 - val_acc: 0.6638\n",
      "Epoch 4/10\n",
      "8375/8375 [==============================] - 379s - loss: 1.7518 - acc: 0.5553 - val_loss: 1.1983 - val_acc: 0.6891\n",
      "Epoch 5/10\n",
      "8375/8375 [==============================] - 417s - loss: 1.6741 - acc: 0.5753 - val_loss: 1.1421 - val_acc: 0.7059\n",
      "Epoch 6/10\n",
      "8375/8375 [==============================] - 419s - loss: 1.6223 - acc: 0.5887 - val_loss: 1.1478 - val_acc: 0.7042\n",
      "Epoch 7/10\n",
      "8375/8375 [==============================] - 420s - loss: 1.5817 - acc: 0.5989 - val_loss: 1.0925 - val_acc: 0.7179\n",
      "Epoch 8/10\n",
      "8375/8375 [==============================] - 419s - loss: 1.5507 - acc: 0.6073 - val_loss: 1.0766 - val_acc: 0.7231\n",
      "Epoch 9/10\n",
      "8375/8375 [==============================] - 419s - loss: 1.5226 - acc: 0.6147 - val_loss: 1.0517 - val_acc: 0.7288\n",
      "Epoch 10/10\n",
      "8375/8375 [==============================] - 418s - loss: 1.5010 - acc: 0.6203 - val_loss: 1.0510 - val_acc: 0.7304\n"
     ]
    }
   ],
   "source": [
    "# Compute quantities required for feature-wise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied).\n",
    "datagen.fit(X_train)\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "data_augmentation = True\n",
    "# num_predictions = 20\n",
    "\n",
    "hist = model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size),\n",
    "                            steps_per_epoch=X_train.shape[0] // batch_size,\n",
    "                            epochs=epochs,\n",
    "#                             callbacks = callbacks,\n",
    "                            validation_data=(X_test, y_test),\n",
    "                            workers=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"QuickDraw_CNN.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start of Image retrival algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input_layer (InputLayer)     (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "Conv01_layer (Conv2D)        (None, 28, 28, 64)        1664      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "Conv02_layer (Conv2D)        (None, 24, 24, 64)        102464    \n",
      "_________________________________________________________________\n",
      "MaxPool01_layer (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "Dropout01_layer (Dropout)    (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "Conv03_layer (Conv2D)        (None, 12, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "Conv04_layer (Conv2D)        (None, 10, 10, 128)       147584    \n",
      "_________________________________________________________________\n",
      "MaxPool02_layer (MaxPooling2 (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "Dropout02_layer (Dropout)    (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "Flatten_layer (Flatten)      (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "Dense01_layer (Dense)        (None, 512)               1638912   \n",
      "_________________________________________________________________\n",
      "Dropout03_layer (Dropout)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "logits_layer (Dense)         (None, 100)               51300     \n",
      "_________________________________________________________________\n",
      "Sofftmax_layer (Activation)  (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 2,018,596\n",
      "Trainable params: 2,017,188\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.get_layer('Conv04_layer').output\n",
    "transformer = Model(model.inputs, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input_layer (InputLayer)     (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "Conv01_layer (Conv2D)        (None, 28, 28, 64)        1664      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "Conv02_layer (Conv2D)        (None, 24, 24, 64)        102464    \n",
      "_________________________________________________________________\n",
      "MaxPool01_layer (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "Dropout01_layer (Dropout)    (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "Conv03_layer (Conv2D)        (None, 12, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "Conv04_layer (Conv2D)        (None, 10, 10, 128)       147584    \n",
      "=================================================================\n",
      "Total params: 326,336\n",
      "Trainable params: 325,952\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transformer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_Vectors = transformer.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_vector = transformer.predict(X_test[0].reshape(1,28,28,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy.linalg import norm\n",
    "ind = np.argmin(norm(X_Vectors-Y_vector[:,None], axis=1, ord=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = X_test[0].reshape([28,28])*255\n",
    "plt.imshow(img)\n",
    "plt.title('Query Image')\n",
    "plt.show()\n",
    "img = X_train[ind].reshape([28,28])*255\n",
    "plt.imshow(img)\n",
    "plt.title('Best found Image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
QuickDraw_CNN.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start of Image retrival algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input_layer (InputLayer)     (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "Conv01_layer (Conv2D)        (None, 28, 28, 64)        1664      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "Conv02_layer (Conv2D)        (None, 24, 24, 64)        102464    \n",
      "_________________________________________________________________\n",
      "MaxPool01_layer (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "Dropout01_layer (Dropout)    (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "Conv03_layer (Conv2D)        (None, 12, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "Conv04_layer (Conv2D)        (None, 10, 10, 128)       147584    \n",
      "_________________________________________________________________\n",
      "MaxPool02_layer (MaxPooling2 (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "Dropout02_layer (Dropout)    (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "Flatten_layer (Flatten)      (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "Dense01_layer (Dense)        (None, 512)               1638912   \n",
      "_________________________________________________________________\n",
      "Dropout03_layer (Dropout)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "logits_layer (Dense)         (None, 100)               51300     \n",
      "_________________________________________________________________\n",
      "Sofftmax_layer (Activation)  (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 2,018,596\n",
      "Trainable params: 2,017,188\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.get_layer('Conv04_layer').output\n",
    "transformer = Model(model.inputs, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input_layer (InputLayer)     (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "Conv01_layer (Conv2D)        (None, 28, 28, 64)        1664      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "Conv02_layer (Conv2D)        (None, 24, 24, 64)        102464    \n",
      "_________________________________________________________________\n",
      "MaxPool01_layer (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "Dropout01_layer (Dropout)    (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "Conv03_layer (Conv2D)        (None, 12, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "Conv04_layer (Conv2D)        (None, 10, 10, 128)       147584    \n",
      "=================================================================\n",
      "Total params: 326,336\n",
      "Trainable params: 325,952\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transformer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-0d81680d2f0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_Vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/nfs/p4/ceusers/limpin/.venv2.7-gpu/local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1711\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1712\u001b[0m         return self._predict_loop(f, ins, batch_size=batch_size,\n\u001b[0;32m-> 1713\u001b[0;31m                                   verbose=verbose, steps=steps)\n\u001b[0m\u001b[1;32m   1714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1715\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/nfs/p4/ceusers/limpin/.venv2.7-gpu/local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1276\u001b[0m                         \u001b[0mouts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_out\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m                     \u001b[0mouts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_start\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_end\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m                     \u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_Vectors = transformer.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_vector = transformer.predict(X_test[0].reshape(1,28,28,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy.linalg import norm\n",
    "ind = np.argmin(norm(X_Vectors-Y_vector[:,None], axis=1, ord=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = X_test[0].reshape([28,28])*255\n",
    "plt.imshow(img)\n",
    "plt.title('Query Image')\n",
    "plt.show()\n",
    "img = X_train[ind].reshape([28,28])*255\n",
    "plt.imshow(img)\n",
    "plt.title('Best found Image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
